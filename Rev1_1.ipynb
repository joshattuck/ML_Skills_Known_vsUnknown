{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7X94Z65wPQh9",
    "outputId": "b06d4fb1-dd11-4178-b334-ebf29fba507e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21uLpmNxWMAZ",
    "outputId": "2da327ef-4a6e-40b5-fa78-6b8873cae0f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/EEG\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Sa3DU3mPWpAo"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/tevisgehr/EEG-Classification.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d_r2yjTtO-Dv",
    "outputId": "f0d66676-621c-4b5c-a847-9b46a9dd6bcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/EEG/EEG-Classification\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My Drive/EEG/EEG-Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VTvQmuLxO8si"
   },
   "outputs": [],
   "source": [
    "from eeg_learn_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "IGeACifsO8ss",
    "outputId": "b79c3a05-2fb7-49aa-d73d-2a4b1bd93055"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as scs\n",
    "import re\n",
    "from numpy import genfromtxt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "plt.rcParams[\"figure.figsize\"] = (12,12)\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.precision = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXgXi2mCO8sz"
   },
   "source": [
    "## Brainwave Frequencies:\n",
    "Gamma, 30 to 50 Hz.  \n",
    "Beta, 14 to 30 Hz.  \n",
    "Alpha, 8 to 14 Hz.  \n",
    "Theta, 4 to 8 Hz.  \n",
    "Delta, 0.1 to 4 Hz.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ek4bBjd7O8s0"
   },
   "source": [
    "## Changing Bin Size: \n",
    "https://stackoverflow.com/questions/25735153/plotting-a-fast-fourier-transform-in-python  \n",
    "(Search for 'bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K618xq-iO8s1"
   },
   "source": [
    "An EEG processing library:  \n",
    "https://github.com/pbashivan/EEGLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "r0JF8FYLO8s2"
   },
   "outputs": [],
   "source": [
    "theta = (4,8)\n",
    "alpha = (8,12)\n",
    "beta = (12,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dltLzYlNO8s6"
   },
   "outputs": [],
   "source": [
    "def get_fft(snippet):\n",
    "    Fs = 128.0;  # sampling rate\n",
    "    #Ts = len(snippet)/Fs/Fs; # sampling interval\n",
    "    snippet_time = len(snippet)/Fs\n",
    "    Ts = 1.0/Fs; # sampling interval\n",
    "    t = np.arange(0,snippet_time,Ts) # time vector\n",
    "\n",
    "    # ff = 5;   # frequency of the signal\n",
    "    # y = np.sin(2*np.pi*ff*t)\n",
    "    y = snippet\n",
    "#     print('Ts: ',Ts)\n",
    "#     print(t)\n",
    "#     print(y.shape)\n",
    "    n = len(y) # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n/Fs\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(n//2)] # one side frequency range\n",
    "\n",
    "    Y = np.fft.fft(y)/n # fft computing and normalization\n",
    "    Y = Y[range(n//2)]\n",
    "    #Added in: (To remove bias.)\n",
    "    #Y[0] = 0\n",
    "    return frq,abs(Y)\n",
    "#f,Y = get_fft(np.hanning(len(snippet))*snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ArxRzbZkO8s-"
   },
   "outputs": [],
   "source": [
    "def theta_alpha_beta_averages(f,Y):\n",
    "    theta_range = (4,8)\n",
    "    alpha_range = (8,12)\n",
    "    beta_range = (12,40)\n",
    "    theta = Y[(f>theta_range[0]) & (f<=theta_range[1])].mean()\n",
    "    alpha = Y[(f>alpha_range[0]) & (f<=alpha_range[1])].mean()\n",
    "    beta = Y[(f>beta_range[0]) & (f<=beta_range[1])].mean()\n",
    "    return theta, alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FYjJuEW-O8tD"
   },
   "outputs": [],
   "source": [
    "def make_steps(samples,frame_duration,overlap):\n",
    "    '''\n",
    "    in:\n",
    "    samples - number of samples in the session\n",
    "    frame_duration - frame duration in seconds \n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "    \n",
    "    out: list of tuple ranges\n",
    "    '''\n",
    "    #steps = np.arange(0,len(df),frame_length)\n",
    "    Fs = 128\n",
    "    i = 0\n",
    "    intervals = []\n",
    "    samples_per_frame = Fs * frame_duration\n",
    "    while i+samples_per_frame <= samples:\n",
    "        intervals.append((i,i+samples_per_frame))\n",
    "        i = i + samples_per_frame - int(samples_per_frame*overlap)\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XDxHBydkO8tH"
   },
   "outputs": [],
   "source": [
    "def make_frames(df,frame_duration):\n",
    "    '''\n",
    "    in: dataframe or array with all channels, frame duration in seconds\n",
    "    out: array of theta, alpha, beta averages for each probe for each time step\n",
    "        shape: (n-frames,m-probes,k-brainwave bands)\n",
    "    '''\n",
    "    Fs = 128.0\n",
    "    frame_length = Fs*frame_duration\n",
    "    frames = []\n",
    "    steps = make_steps(len(df),frame_duration,overlap)\n",
    "    for i,_ in enumerate(steps):\n",
    "        frame = []\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else:\n",
    "            for channel in df.columns:\n",
    "                snippet = np.array(df.loc[steps[i][0]:steps[i][1],int(channel)])\n",
    "                f,Y =  get_fft(snippet)\n",
    "                theta, alpha, beta = theta_alpha_beta_averages(f,Y)\n",
    "                frame.append([theta, alpha, beta])\n",
    "            \n",
    "        frames.append(frame)\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "I_PVRz3cO8tL"
   },
   "outputs": [],
   "source": [
    "locs_2d = [(-2.0,4.0),\n",
    "           (2.0,4.0),\n",
    "           (-1.0,3.0),\n",
    "           (1.0,3.0),\n",
    "           (-3.0,3.0),\n",
    "           (3.0,3.0),\n",
    "           (-2.0,2.0),\n",
    "           (2.0,2.0),\n",
    "           (-2.0,-2.0),\n",
    "           (2.0,-2.0),\n",
    "           (-4.0,1.0),\n",
    "           (4.0,1.0),\n",
    "           (-1.0,-3.0),\n",
    "           (1.0,-3.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "kaxl_jjyO8tQ"
   },
   "outputs": [],
   "source": [
    "def make_data_pipeline(file_names,labels,image_size,frame_duration,overlap):\n",
    "    '''\n",
    "    IN: \n",
    "    file_names - list of strings for each input file (one for each subject)\n",
    "    labels - list of labels for each\n",
    "    image_size - int size of output images in form (x, x)\n",
    "    frame_duration - time length of each frame (seconds)\n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "    \n",
    "    OUT:\n",
    "    X: np array of frames (unshuffled)\n",
    "    y: np array of label for each frame (1 or 0)\n",
    "    '''\n",
    "    ##################################\n",
    "    ###Still need to do the overlap###!!!\n",
    "    ##################################\n",
    "    \n",
    "    Fs = 128.0   #sampling rate\n",
    "    frame_length = Fs * frame_duration\n",
    "    \n",
    "    print('Generating training data...')\n",
    "    \n",
    "    \n",
    "    for i, file in enumerate(file_names):\n",
    "        print ('Processing session: ',file, '. (',i+1,' of ',len(file_names),')')\n",
    "        data = genfromtxt(file, delimiter=',').T\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        X_0 = make_frames(df,frame_duration)\n",
    "        #steps = np.arange(0,len(df),frame_length)\n",
    "        X_1 = X_0.reshape(len(X_0),14*3)\n",
    "        \n",
    "        images = gen_images(np.array(locs_2d),X_1, image_size, normalize=False)\n",
    "        images = np.swapaxes(images, 1, 3) \n",
    "        print(len(images), ' frames generated with label ', labels[i], '.')\n",
    "        print('\\n')\n",
    "        if i == 0:\n",
    "            X = images\n",
    "            y = np.ones(len(images))*labels[0]\n",
    "        else:\n",
    "            X = np.concatenate((X,images),axis = 0)\n",
    "            y = np.concatenate((y,np.ones(len(images))*labels[i]),axis = 0)\n",
    "        \n",
    "        \n",
    "    return X,np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pHo32n8TXT5x"
   },
   "outputs": [],
   "source": [
    "# !unzip data_new.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UyS9SFf9O8tT",
    "outputId": "25917ccd-1c1e-46e1-b4e9-b8ead224f3e1",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data...\n",
      "Processing session:  data/ML101_KS.csv . ( 1  of  40 )\n",
      "234  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML101_US.csv . ( 2  of  40 )\n",
      "224  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML102_KS.csv . ( 3  of  40 )\n",
      "222  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML102_US.csv . ( 4  of  40 )\n",
      "218  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML103_KS.csv . ( 5  of  40 )\n",
      "226  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML103_US.csv . ( 6  of  40 )\n",
      "208  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML104_KS.csv . ( 7  of  40 )\n",
      "202  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML104_US.csv . ( 8  of  40 )\n",
      "204  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML105_KS.csv . ( 9  of  40 )\n",
      "214  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML105_US.csv . ( 10  of  40 )\n",
      "226  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML106_KS.csv . ( 11  of  40 )\n",
      "230  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML106_US.csv . ( 12  of  40 )\n",
      "278  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML107_KS.csv . ( 13  of  40 )\n",
      "246  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML107_US.csv . ( 14  of  40 )\n",
      "236  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML108_KS.csv . ( 15  of  40 )\n",
      "240  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML108_US.csv . ( 16  of  40 )\n",
      "234  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML109_KS.csv . ( 17  of  40 )\n",
      "258  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML109_US.csv . ( 18  of  40 )\n",
      "246  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML110_KS.csv . ( 19  of  40 )\n",
      "240  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML110_US.csv . ( 20  of  40 )\n",
      "216  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML111_KS.csv . ( 21  of  40 )\n",
      "232  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML111_US.csv . ( 22  of  40 )\n",
      "238  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML112_KS.csv . ( 23  of  40 )\n",
      "253  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML112_US.csv . ( 24  of  40 )\n",
      "252  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML113_KS.csv . ( 25  of  40 )\n",
      "168  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML113_US.csv . ( 26  of  40 )\n",
      "156  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML114_KS.csv . ( 27  of  40 )\n",
      "218  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML114_US.csv . ( 28  of  40 )\n",
      "224  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML115_KS.csv . ( 29  of  40 )\n",
      "248  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML115_US.csv . ( 30  of  40 )\n",
      "243  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML116_KS.csv . ( 31  of  40 )\n",
      "240  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML116_US.csv . ( 32  of  40 )\n",
      "242  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML118_KS.csv . ( 33  of  40 )\n",
      "248  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML118_US.csv . ( 34  of  40 )\n",
      "245  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML119_KS.csv . ( 35  of  40 )\n",
      "242  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML119_US.csv . ( 36  of  40 )\n",
      "248  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML120_KS.csv . ( 37  of  40 )\n",
      "240  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML120_US.csv . ( 38  of  40 )\n",
      "237  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML121_KS.csv . ( 39  of  40 )\n",
      "261  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data_new/ML121_US.csv . ( 40  of  40 )\n",
      "246  frames generated with label  0 .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_names = ['data/ML101_KS.csv',\n",
    "              'data/ML101_US.csv',\n",
    "              'data/ML102_KS.csv',\n",
    "              'data/ML102_US.csv',\n",
    "              'data/ML103_KS.csv',\n",
    "              'data/ML103_US.csv',\n",
    "              'data/ML104_KS.csv',\n",
    "              'data/ML104_US.csv',\n",
    "              'data/ML105_KS.csv',\n",
    "              'data/ML105_US.csv',\n",
    "              'data/ML106_KS.csv',\n",
    "              'data/ML106_US.csv',\n",
    "              'data/ML107_KS.csv',\n",
    "              'data/ML107_US.csv',\n",
    "              'data/ML108_KS.csv',\n",
    "              'data/ML108_US.csv', \n",
    "              'data_new/ML109_KS.csv',\n",
    "              'data_new/ML109_US.csv',\n",
    "              'data_new/ML110_KS.csv',\n",
    "              'data_new/ML110_US.csv',\n",
    "              'data_new/ML111_KS.csv',\n",
    "              'data_new/ML111_US.csv',\n",
    "              'data_new/ML112_KS.csv',\n",
    "              'data_new/ML112_US.csv',\n",
    "              'data_new/ML113_KS.csv',\n",
    "              'data_new/ML113_US.csv',\n",
    "              'data_new/ML114_KS.csv',\n",
    "              'data_new/ML114_US.csv',\n",
    "              'data_new/ML115_KS.csv',\n",
    "              'data_new/ML115_US.csv',\n",
    "              'data_new/ML116_KS.csv',\n",
    "              'data_new/ML116_US.csv',\n",
    "              'data_new/ML118_KS.csv',\n",
    "              'data_new/ML118_US.csv',\n",
    "              'data_new/ML119_KS.csv',\n",
    "              'data_new/ML119_US.csv',\n",
    "              'data_new/ML120_KS.csv',\n",
    "              'data_new/ML120_US.csv',\n",
    "              'data_new/ML121_KS.csv',\n",
    "              'data_new/ML121_US.csv']\n",
    "labels = [1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0]\n",
    "image_size = 28\n",
    "frame_duration = 1.0\n",
    "overlap = 0.5\n",
    "X, y = make_data_pipeline(file_names,labels,image_size,frame_duration,overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgLeYPiJO8tX",
    "outputId": "f60fd223-1f2f-4638-d033-6b952e9dbc23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9283, 28, 28, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DAIbXq9CO8tb",
    "outputId": "b3e8c57c-9996-4edd-e4f4-1301aa429691"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9283,)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "Zbd1Wt22O8tf",
    "outputId": "7f0831e8-773a-44bb-8f89-2a79bff3bbe7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "hvatn3pxO8tj",
    "outputId": "c2b35c5f-f79f-4e68-df3f-fff89843495c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Two subplots, the axes array is 1-d\n",
    "f, axarr = plt.subplots(2,2, figsize = (8,8))\n",
    "axarr[0][0].set_title('Known Skill')\n",
    "axarr[0][0].imshow(X[0])\n",
    "axarr[1][0].imshow(X[1])\n",
    "\n",
    "axarr[0][1].set_title('Unknown Skill')\n",
    "axarr[0][1].imshow(X[20])\n",
    "axarr[1][1].imshow(X[21])\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1i4fpi_2O8tt"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "usrLlQxOO8tx",
    "outputId": "790f9994-5bbb-4e29-f044-1b20fdb27975"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7426,)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qmm-cqbuO8t1",
    "outputId": "f01e617f-6f12-4183-8bc0-a9925afea031"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (7426, 28, 28, 3)\n",
      "7426 train samples\n",
      "1857 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DhCUgfwMO8t4",
    "outputId": "9396be10-5721-4d6b-84a6-869da82b0996",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "59/59 [==============================] - 1s 19ms/step - loss: 0.9928 - accuracy: 0.5158\n",
      "Epoch 2/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.7078 - accuracy: 0.5338\n",
      "Epoch 3/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.6973 - accuracy: 0.5494\n",
      "Epoch 4/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.6848 - accuracy: 0.5681\n",
      "Epoch 5/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.6727 - accuracy: 0.5897\n",
      "Epoch 6/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.6644 - accuracy: 0.5900\n",
      "Epoch 7/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.6530 - accuracy: 0.6204\n",
      "Epoch 8/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.6467 - accuracy: 0.6169\n",
      "Epoch 9/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.6263 - accuracy: 0.6407\n",
      "Epoch 10/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.6215 - accuracy: 0.6457\n",
      "Epoch 11/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.6123 - accuracy: 0.6619\n",
      "Epoch 12/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.5961 - accuracy: 0.6648\n",
      "Epoch 13/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.5849 - accuracy: 0.6848\n",
      "Epoch 14/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.5879 - accuracy: 0.6748\n",
      "Epoch 15/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.5734 - accuracy: 0.7009\n",
      "Epoch 16/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.5663 - accuracy: 0.7032\n",
      "Epoch 17/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.5461 - accuracy: 0.7152\n",
      "Epoch 18/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.5435 - accuracy: 0.7179\n",
      "Epoch 19/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.5387 - accuracy: 0.7219\n",
      "Epoch 20/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.5302 - accuracy: 0.7234\n",
      "Epoch 21/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.5245 - accuracy: 0.7377\n",
      "Epoch 22/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.5188 - accuracy: 0.7390\n",
      "Epoch 23/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.4945 - accuracy: 0.7555\n",
      "Epoch 24/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.5010 - accuracy: 0.7468\n",
      "Epoch 25/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.4785 - accuracy: 0.7604\n",
      "Epoch 26/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.4717 - accuracy: 0.7661\n",
      "Epoch 27/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.4677 - accuracy: 0.7673\n",
      "Epoch 28/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.4652 - accuracy: 0.7722\n",
      "Epoch 29/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.4615 - accuracy: 0.7783\n",
      "Epoch 30/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.4507 - accuracy: 0.7775\n",
      "Epoch 31/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.4454 - accuracy: 0.7789\n",
      "Epoch 32/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.4417 - accuracy: 0.7893\n",
      "Epoch 33/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.4308 - accuracy: 0.7969\n",
      "Epoch 34/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.4208 - accuracy: 0.7994\n",
      "Epoch 35/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.4346 - accuracy: 0.7905\n",
      "Epoch 36/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.4177 - accuracy: 0.8015\n",
      "Epoch 37/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.4057 - accuracy: 0.8095\n",
      "Epoch 38/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.4013 - accuracy: 0.8146\n",
      "Epoch 39/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.3923 - accuracy: 0.8213\n",
      "Epoch 40/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3849 - accuracy: 0.8202\n",
      "Epoch 41/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3782 - accuracy: 0.8240\n",
      "Epoch 42/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3739 - accuracy: 0.8286\n",
      "Epoch 43/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3782 - accuracy: 0.8227\n",
      "Epoch 44/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3643 - accuracy: 0.8327\n",
      "Epoch 45/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3561 - accuracy: 0.8344\n",
      "Epoch 46/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3513 - accuracy: 0.8388\n",
      "Epoch 47/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3479 - accuracy: 0.8430\n",
      "Epoch 48/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3354 - accuracy: 0.8473\n",
      "Epoch 49/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3241 - accuracy: 0.8558\n",
      "Epoch 50/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3303 - accuracy: 0.8484\n",
      "Epoch 51/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3222 - accuracy: 0.8582\n",
      "Epoch 52/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3161 - accuracy: 0.8639\n",
      "Epoch 53/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3016 - accuracy: 0.8687\n",
      "Epoch 54/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3028 - accuracy: 0.8683\n",
      "Epoch 55/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3017 - accuracy: 0.8699\n",
      "Epoch 56/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.3020 - accuracy: 0.8679\n",
      "Epoch 57/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2881 - accuracy: 0.8771\n",
      "Epoch 58/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2813 - accuracy: 0.8810\n",
      "Epoch 59/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2695 - accuracy: 0.8823\n",
      "Epoch 60/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2676 - accuracy: 0.8851\n",
      "Epoch 61/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2601 - accuracy: 0.8917\n",
      "Epoch 62/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2533 - accuracy: 0.8932\n",
      "Epoch 63/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2600 - accuracy: 0.8888\n",
      "Epoch 64/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2440 - accuracy: 0.8989\n",
      "Epoch 65/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2403 - accuracy: 0.9010\n",
      "Epoch 66/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2477 - accuracy: 0.8944\n",
      "Epoch 67/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2395 - accuracy: 0.9016\n",
      "Epoch 68/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2273 - accuracy: 0.9041\n",
      "Epoch 69/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2203 - accuracy: 0.9092\n",
      "Epoch 70/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2160 - accuracy: 0.9153\n",
      "Epoch 71/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2243 - accuracy: 0.9060\n",
      "Epoch 72/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2031 - accuracy: 0.9196\n",
      "Epoch 73/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2013 - accuracy: 0.9200\n",
      "Epoch 74/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.2086 - accuracy: 0.9162\n",
      "Epoch 75/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.1974 - accuracy: 0.9254\n",
      "Epoch 76/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1984 - accuracy: 0.9203\n",
      "Epoch 77/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1963 - accuracy: 0.9250\n",
      "Epoch 78/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1820 - accuracy: 0.9315\n",
      "Epoch 79/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1923 - accuracy: 0.9254\n",
      "Epoch 80/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1824 - accuracy: 0.9321\n",
      "Epoch 81/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1670 - accuracy: 0.9371\n",
      "Epoch 82/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1761 - accuracy: 0.9346\n",
      "Epoch 83/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1638 - accuracy: 0.9378\n",
      "Epoch 84/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1595 - accuracy: 0.9377\n",
      "Epoch 85/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1667 - accuracy: 0.9352\n",
      "Epoch 86/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1561 - accuracy: 0.9413\n",
      "Epoch 87/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1482 - accuracy: 0.9428\n",
      "Epoch 88/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1567 - accuracy: 0.9395\n",
      "Epoch 89/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1565 - accuracy: 0.9417\n",
      "Epoch 90/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1516 - accuracy: 0.9441\n",
      "Epoch 91/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1461 - accuracy: 0.9459\n",
      "Epoch 92/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1402 - accuracy: 0.9482\n",
      "Epoch 93/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1340 - accuracy: 0.9508\n",
      "Epoch 94/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1469 - accuracy: 0.9426\n",
      "Epoch 95/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1363 - accuracy: 0.9460\n",
      "Epoch 96/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1312 - accuracy: 0.9508\n",
      "Epoch 97/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1376 - accuracy: 0.9482\n",
      "Epoch 98/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1226 - accuracy: 0.9530\n",
      "Epoch 99/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1297 - accuracy: 0.9526\n",
      "Epoch 100/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1239 - accuracy: 0.9565\n",
      "Epoch 101/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1298 - accuracy: 0.9554\n",
      "Epoch 102/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1209 - accuracy: 0.9556\n",
      "Epoch 103/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1228 - accuracy: 0.9549\n",
      "Epoch 104/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1298 - accuracy: 0.9510\n",
      "Epoch 105/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1111 - accuracy: 0.9599\n",
      "Epoch 106/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1199 - accuracy: 0.9566\n",
      "Epoch 107/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1186 - accuracy: 0.9569\n",
      "Epoch 108/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1128 - accuracy: 0.9609\n",
      "Epoch 109/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.1178 - accuracy: 0.9556\n",
      "Epoch 110/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1089 - accuracy: 0.9631\n",
      "Epoch 111/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1147 - accuracy: 0.9601\n",
      "Epoch 112/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1069 - accuracy: 0.9630\n",
      "Epoch 113/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1002 - accuracy: 0.9654\n",
      "Epoch 114/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.1153 - accuracy: 0.9549\n",
      "Epoch 115/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1025 - accuracy: 0.9638\n",
      "Epoch 116/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1000 - accuracy: 0.9635\n",
      "Epoch 117/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0982 - accuracy: 0.9644\n",
      "Epoch 118/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0946 - accuracy: 0.9670\n",
      "Epoch 119/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1004 - accuracy: 0.9634\n",
      "Epoch 120/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0996 - accuracy: 0.9627\n",
      "Epoch 121/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0920 - accuracy: 0.9680\n",
      "Epoch 122/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.1043 - accuracy: 0.9624\n",
      "Epoch 123/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0941 - accuracy: 0.9665\n",
      "Epoch 124/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0925 - accuracy: 0.9682\n",
      "Epoch 125/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0902 - accuracy: 0.9693\n",
      "Epoch 126/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0850 - accuracy: 0.9731\n",
      "Epoch 127/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0922 - accuracy: 0.9651\n",
      "Epoch 128/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0826 - accuracy: 0.9715\n",
      "Epoch 129/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0821 - accuracy: 0.9704\n",
      "Epoch 130/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0856 - accuracy: 0.9696\n",
      "Epoch 131/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0808 - accuracy: 0.9720\n",
      "Epoch 132/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0791 - accuracy: 0.9735\n",
      "Epoch 133/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0867 - accuracy: 0.9690\n",
      "Epoch 134/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0745 - accuracy: 0.9727\n",
      "Epoch 135/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0806 - accuracy: 0.9698\n",
      "Epoch 136/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0823 - accuracy: 0.9721\n",
      "Epoch 137/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0809 - accuracy: 0.9706\n",
      "Epoch 138/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0812 - accuracy: 0.9719\n",
      "Epoch 139/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0746 - accuracy: 0.9732\n",
      "Epoch 140/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0741 - accuracy: 0.9748\n",
      "Epoch 141/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0751 - accuracy: 0.9740\n",
      "Epoch 142/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0818 - accuracy: 0.9712\n",
      "Epoch 143/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0730 - accuracy: 0.9727\n",
      "Epoch 144/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0781 - accuracy: 0.9713\n",
      "Epoch 145/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0727 - accuracy: 0.9732\n",
      "Epoch 146/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0757 - accuracy: 0.9744\n",
      "Epoch 147/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0768 - accuracy: 0.9747\n",
      "Epoch 148/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0754 - accuracy: 0.9739\n",
      "Epoch 149/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0750 - accuracy: 0.9732\n",
      "Epoch 150/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0855 - accuracy: 0.9702\n",
      "Epoch 151/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0715 - accuracy: 0.9752\n",
      "Epoch 152/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0853 - accuracy: 0.9705\n",
      "Epoch 153/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0854 - accuracy: 0.9697\n",
      "Epoch 154/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0696 - accuracy: 0.9770\n",
      "Epoch 155/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0665 - accuracy: 0.9767\n",
      "Epoch 156/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0656 - accuracy: 0.9774\n",
      "Epoch 157/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0708 - accuracy: 0.9743\n",
      "Epoch 158/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0757 - accuracy: 0.9724\n",
      "Epoch 159/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0671 - accuracy: 0.9759\n",
      "Epoch 160/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0795 - accuracy: 0.9704\n",
      "Epoch 161/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0700 - accuracy: 0.9752\n",
      "Epoch 162/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0726 - accuracy: 0.9755\n",
      "Epoch 163/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0665 - accuracy: 0.9766\n",
      "Epoch 164/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0669 - accuracy: 0.9759\n",
      "Epoch 165/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0700 - accuracy: 0.9759\n",
      "Epoch 166/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0771 - accuracy: 0.9700\n",
      "Epoch 167/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0638 - accuracy: 0.9779\n",
      "Epoch 168/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0739 - accuracy: 0.9733\n",
      "Epoch 169/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0690 - accuracy: 0.9740\n",
      "Epoch 170/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0638 - accuracy: 0.9770\n",
      "Epoch 171/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0663 - accuracy: 0.9763\n",
      "Epoch 172/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0681 - accuracy: 0.9756\n",
      "Epoch 173/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0807 - accuracy: 0.9674\n",
      "Epoch 174/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0610 - accuracy: 0.9793\n",
      "Epoch 175/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0693 - accuracy: 0.9760\n",
      "Epoch 176/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0643 - accuracy: 0.9763\n",
      "Epoch 177/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0614 - accuracy: 0.9789\n",
      "Epoch 178/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0649 - accuracy: 0.9778\n",
      "Epoch 179/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0671 - accuracy: 0.9770\n",
      "Epoch 180/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0612 - accuracy: 0.9764\n",
      "Epoch 181/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0625 - accuracy: 0.9764\n",
      "Epoch 182/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0702 - accuracy: 0.9735\n",
      "Epoch 183/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0653 - accuracy: 0.9762\n",
      "Epoch 184/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0679 - accuracy: 0.9760\n",
      "Epoch 185/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0633 - accuracy: 0.9781\n",
      "Epoch 186/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0652 - accuracy: 0.9789\n",
      "Epoch 187/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0570 - accuracy: 0.9818\n",
      "Epoch 188/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0523 - accuracy: 0.9824\n",
      "Epoch 189/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0636 - accuracy: 0.9767\n",
      "Epoch 190/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0580 - accuracy: 0.9803\n",
      "Epoch 191/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0602 - accuracy: 0.9778\n",
      "Epoch 192/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0522 - accuracy: 0.9830\n",
      "Epoch 193/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0586 - accuracy: 0.9776\n",
      "Epoch 194/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0547 - accuracy: 0.9817\n",
      "Epoch 195/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0565 - accuracy: 0.9807\n",
      "Epoch 196/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0535 - accuracy: 0.9824\n",
      "Epoch 197/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0541 - accuracy: 0.9802\n",
      "Epoch 198/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0626 - accuracy: 0.9764\n",
      "Epoch 199/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0582 - accuracy: 0.9798\n",
      "Epoch 200/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0564 - accuracy: 0.9807\n",
      "Epoch 201/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0563 - accuracy: 0.9805\n",
      "Epoch 202/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0616 - accuracy: 0.9772\n",
      "Epoch 203/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0592 - accuracy: 0.9779\n",
      "Epoch 204/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0516 - accuracy: 0.9795\n",
      "Epoch 205/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0591 - accuracy: 0.9809\n",
      "Epoch 206/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0483 - accuracy: 0.9824\n",
      "Epoch 207/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0564 - accuracy: 0.9803\n",
      "Epoch 208/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0534 - accuracy: 0.9816\n",
      "Epoch 209/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0527 - accuracy: 0.9810\n",
      "Epoch 210/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0537 - accuracy: 0.9821\n",
      "Epoch 211/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0588 - accuracy: 0.9794\n",
      "Epoch 212/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0555 - accuracy: 0.9798\n",
      "Epoch 213/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0570 - accuracy: 0.9801\n",
      "Epoch 214/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0555 - accuracy: 0.9797\n",
      "Epoch 215/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0549 - accuracy: 0.9801\n",
      "Epoch 216/400\n",
      "59/59 [==============================] - 1s 18ms/step - loss: 0.0478 - accuracy: 0.9842\n",
      "Epoch 217/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0549 - accuracy: 0.9805\n",
      "Epoch 218/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0537 - accuracy: 0.9798\n",
      "Epoch 219/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0476 - accuracy: 0.9830\n",
      "Epoch 220/400\n",
      "59/59 [==============================] - 1s 18ms/step - loss: 0.0485 - accuracy: 0.9813\n",
      "Epoch 221/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0547 - accuracy: 0.9794\n",
      "Epoch 222/400\n",
      "59/59 [==============================] - 1s 18ms/step - loss: 0.0500 - accuracy: 0.9807\n",
      "Epoch 223/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0584 - accuracy: 0.9791\n",
      "Epoch 224/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0476 - accuracy: 0.9825\n",
      "Epoch 225/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0498 - accuracy: 0.9813\n",
      "Epoch 226/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0498 - accuracy: 0.9809\n",
      "Epoch 227/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0544 - accuracy: 0.9806\n",
      "Epoch 228/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0538 - accuracy: 0.9817\n",
      "Epoch 229/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0507 - accuracy: 0.9814\n",
      "Epoch 230/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0513 - accuracy: 0.9825\n",
      "Epoch 231/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0516 - accuracy: 0.9805\n",
      "Epoch 232/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0498 - accuracy: 0.9813\n",
      "Epoch 233/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0497 - accuracy: 0.9828\n",
      "Epoch 234/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0499 - accuracy: 0.9825\n",
      "Epoch 235/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0449 - accuracy: 0.9840\n",
      "Epoch 236/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0462 - accuracy: 0.9849\n",
      "Epoch 237/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0471 - accuracy: 0.9837\n",
      "Epoch 238/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0479 - accuracy: 0.9837\n",
      "Epoch 239/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0469 - accuracy: 0.9836\n",
      "Epoch 240/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0504 - accuracy: 0.9818\n",
      "Epoch 241/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0461 - accuracy: 0.9833\n",
      "Epoch 242/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0509 - accuracy: 0.9813\n",
      "Epoch 243/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0503 - accuracy: 0.9836\n",
      "Epoch 244/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0507 - accuracy: 0.9824\n",
      "Epoch 245/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0542 - accuracy: 0.9789\n",
      "Epoch 246/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0496 - accuracy: 0.9810\n",
      "Epoch 247/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0475 - accuracy: 0.9841\n",
      "Epoch 248/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0497 - accuracy: 0.9814\n",
      "Epoch 249/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0502 - accuracy: 0.9833\n",
      "Epoch 250/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0531 - accuracy: 0.9801\n",
      "Epoch 251/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0510 - accuracy: 0.9825\n",
      "Epoch 252/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0497 - accuracy: 0.9820\n",
      "Epoch 253/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0422 - accuracy: 0.9855\n",
      "Epoch 254/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0481 - accuracy: 0.9841\n",
      "Epoch 255/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0532 - accuracy: 0.9814\n",
      "Epoch 256/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0510 - accuracy: 0.9822\n",
      "Epoch 257/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0459 - accuracy: 0.9846\n",
      "Epoch 258/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0515 - accuracy: 0.9811\n",
      "Epoch 259/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0580 - accuracy: 0.9772\n",
      "Epoch 260/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0525 - accuracy: 0.9790\n",
      "Epoch 261/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0544 - accuracy: 0.9802\n",
      "Epoch 262/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0427 - accuracy: 0.9848\n",
      "Epoch 263/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0387 - accuracy: 0.9869\n",
      "Epoch 264/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0417 - accuracy: 0.9865\n",
      "Epoch 265/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0507 - accuracy: 0.9810\n",
      "Epoch 266/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0491 - accuracy: 0.9825\n",
      "Epoch 267/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0481 - accuracy: 0.9814\n",
      "Epoch 268/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0522 - accuracy: 0.9801\n",
      "Epoch 269/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0570 - accuracy: 0.9783\n",
      "Epoch 270/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0444 - accuracy: 0.9832\n",
      "Epoch 271/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0522 - accuracy: 0.9820\n",
      "Epoch 272/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0561 - accuracy: 0.9809\n",
      "Epoch 273/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0521 - accuracy: 0.9798\n",
      "Epoch 274/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0461 - accuracy: 0.9834\n",
      "Epoch 275/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0448 - accuracy: 0.9841\n",
      "Epoch 276/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0489 - accuracy: 0.9830\n",
      "Epoch 277/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0549 - accuracy: 0.9807\n",
      "Epoch 278/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0446 - accuracy: 0.9841\n",
      "Epoch 279/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0385 - accuracy: 0.9881\n",
      "Epoch 280/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0415 - accuracy: 0.9856\n",
      "Epoch 281/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0471 - accuracy: 0.9837\n",
      "Epoch 282/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0471 - accuracy: 0.9838\n",
      "Epoch 283/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0440 - accuracy: 0.9851\n",
      "Epoch 284/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0415 - accuracy: 0.9855\n",
      "Epoch 285/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0460 - accuracy: 0.9832\n",
      "Epoch 286/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0375 - accuracy: 0.9860\n",
      "Epoch 287/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0392 - accuracy: 0.9861\n",
      "Epoch 288/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0373 - accuracy: 0.9873\n",
      "Epoch 289/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0396 - accuracy: 0.9857\n",
      "Epoch 290/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0458 - accuracy: 0.9833\n",
      "Epoch 291/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0371 - accuracy: 0.9869\n",
      "Epoch 292/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0463 - accuracy: 0.9828\n",
      "Epoch 293/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0416 - accuracy: 0.9857\n",
      "Epoch 294/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0411 - accuracy: 0.9860\n",
      "Epoch 295/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0439 - accuracy: 0.9841\n",
      "Epoch 296/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0429 - accuracy: 0.9836\n",
      "Epoch 297/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0363 - accuracy: 0.9872\n",
      "Epoch 298/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0380 - accuracy: 0.9859\n",
      "Epoch 299/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0423 - accuracy: 0.9846\n",
      "Epoch 300/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0415 - accuracy: 0.9855\n",
      "Epoch 301/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0473 - accuracy: 0.9822\n",
      "Epoch 302/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0348 - accuracy: 0.9869\n",
      "Epoch 303/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0396 - accuracy: 0.9856\n",
      "Epoch 304/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0397 - accuracy: 0.9861\n",
      "Epoch 305/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0397 - accuracy: 0.9863\n",
      "Epoch 306/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0355 - accuracy: 0.9877\n",
      "Epoch 307/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0470 - accuracy: 0.9824\n",
      "Epoch 308/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0489 - accuracy: 0.9824\n",
      "Epoch 309/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0407 - accuracy: 0.9851\n",
      "Epoch 310/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0389 - accuracy: 0.9863\n",
      "Epoch 311/400\n",
      "59/59 [==============================] - 1s 18ms/step - loss: 0.0368 - accuracy: 0.9856\n",
      "Epoch 312/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0451 - accuracy: 0.9844\n",
      "Epoch 313/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0466 - accuracy: 0.9834\n",
      "Epoch 314/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0427 - accuracy: 0.9859\n",
      "Epoch 315/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0392 - accuracy: 0.9873\n",
      "Epoch 316/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0456 - accuracy: 0.9834\n",
      "Epoch 317/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0429 - accuracy: 0.9842\n",
      "Epoch 318/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0372 - accuracy: 0.9871\n",
      "Epoch 319/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0385 - accuracy: 0.9864\n",
      "Epoch 320/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0345 - accuracy: 0.9902\n",
      "Epoch 321/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0416 - accuracy: 0.9844\n",
      "Epoch 322/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0339 - accuracy: 0.9881\n",
      "Epoch 323/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0379 - accuracy: 0.9871\n",
      "Epoch 324/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0490 - accuracy: 0.9825\n",
      "Epoch 325/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0395 - accuracy: 0.9861\n",
      "Epoch 326/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0360 - accuracy: 0.9868\n",
      "Epoch 327/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0374 - accuracy: 0.9863\n",
      "Epoch 328/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0377 - accuracy: 0.9869\n",
      "Epoch 329/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0427 - accuracy: 0.9849\n",
      "Epoch 330/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0354 - accuracy: 0.9884\n",
      "Epoch 331/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0301 - accuracy: 0.9902\n",
      "Epoch 333/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0407 - accuracy: 0.9857\n",
      "Epoch 334/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0383 - accuracy: 0.9856\n",
      "Epoch 335/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0364 - accuracy: 0.9880\n",
      "Epoch 336/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0346 - accuracy: 0.9861\n",
      "Epoch 337/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0329 - accuracy: 0.9887\n",
      "Epoch 338/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0326 - accuracy: 0.9896\n",
      "Epoch 339/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0349 - accuracy: 0.9869\n",
      "Epoch 340/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0429 - accuracy: 0.9840\n",
      "Epoch 341/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0373 - accuracy: 0.9863\n",
      "Epoch 342/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0396 - accuracy: 0.9868\n",
      "Epoch 343/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0418 - accuracy: 0.9849\n",
      "Epoch 344/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0355 - accuracy: 0.9879\n",
      "Epoch 345/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0416 - accuracy: 0.9846\n",
      "Epoch 346/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0469 - accuracy: 0.9833\n",
      "Epoch 347/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0389 - accuracy: 0.9868\n",
      "Epoch 348/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0512 - accuracy: 0.9816\n",
      "Epoch 349/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0383 - accuracy: 0.9848\n",
      "Epoch 350/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0425 - accuracy: 0.9852\n",
      "Epoch 351/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0384 - accuracy: 0.9864\n",
      "Epoch 352/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0348 - accuracy: 0.9879\n",
      "Epoch 353/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0428 - accuracy: 0.9851\n",
      "Epoch 354/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0356 - accuracy: 0.9881\n",
      "Epoch 355/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0458 - accuracy: 0.9849\n",
      "Epoch 356/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0393 - accuracy: 0.9859\n",
      "Epoch 357/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0349 - accuracy: 0.9884\n",
      "Epoch 358/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0439 - accuracy: 0.9838\n",
      "Epoch 359/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0480 - accuracy: 0.9813\n",
      "Epoch 360/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0367 - accuracy: 0.9875\n",
      "Epoch 361/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0393 - accuracy: 0.9864\n",
      "Epoch 362/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0417 - accuracy: 0.9846\n",
      "Epoch 363/400\n",
      "59/59 [==============================] - 1s 16ms/step - loss: 0.0422 - accuracy: 0.9836\n",
      "Epoch 364/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0420 - accuracy: 0.9845\n",
      "Epoch 365/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0387 - accuracy: 0.9868\n",
      "Epoch 366/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0398 - accuracy: 0.9873\n",
      "Epoch 367/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0375 - accuracy: 0.9873\n",
      "Epoch 368/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0392 - accuracy: 0.9861\n",
      "Epoch 369/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0378 - accuracy: 0.9864\n",
      "Epoch 370/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0284 - accuracy: 0.9896\n",
      "Epoch 371/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0334 - accuracy: 0.9888\n",
      "Epoch 372/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0359 - accuracy: 0.9872\n",
      "Epoch 373/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0410 - accuracy: 0.9852\n",
      "Epoch 374/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0394 - accuracy: 0.9846\n",
      "Epoch 375/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0383 - accuracy: 0.9865\n",
      "Epoch 376/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0379 - accuracy: 0.9868\n",
      "Epoch 377/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0423 - accuracy: 0.9844\n",
      "Epoch 378/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0425 - accuracy: 0.9848\n",
      "Epoch 379/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0524 - accuracy: 0.9806\n",
      "Epoch 380/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0409 - accuracy: 0.9845\n",
      "Epoch 381/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0417 - accuracy: 0.9849\n",
      "Epoch 382/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0305 - accuracy: 0.9895\n",
      "Epoch 383/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0393 - accuracy: 0.9872\n",
      "Epoch 384/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0312 - accuracy: 0.9892\n",
      "Epoch 385/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0345 - accuracy: 0.9883\n",
      "Epoch 386/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0381 - accuracy: 0.9877\n",
      "Epoch 387/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0379 - accuracy: 0.9867\n",
      "Epoch 388/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0377 - accuracy: 0.9867\n",
      "Epoch 389/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0370 - accuracy: 0.9856\n",
      "Epoch 390/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0357 - accuracy: 0.9877\n",
      "Epoch 391/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0382 - accuracy: 0.9856\n",
      "Epoch 392/400\n",
      "59/59 [==============================] - 1s 18ms/step - loss: 0.0329 - accuracy: 0.9883\n",
      "Epoch 393/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0395 - accuracy: 0.9859\n",
      "Epoch 394/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0288 - accuracy: 0.9896\n",
      "Epoch 395/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0337 - accuracy: 0.9880\n",
      "Epoch 396/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0354 - accuracy: 0.9879\n",
      "Epoch 397/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0342 - accuracy: 0.9877\n",
      "Epoch 398/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0321 - accuracy: 0.9895\n",
      "Epoch 399/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0324 - accuracy: 0.9881\n",
      "Epoch 400/400\n",
      "59/59 [==============================] - 1s 17ms/step - loss: 0.0257 - accuracy: 0.9899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff6d00f9c88>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 400\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.30))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.RMSprop(lr=0.0007, decay=1e-5)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training accuracy you see here, has gone as high as 98% but, our concern is always the test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the test accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9O-RXogSO8t8"
   },
   "outputs": [],
   "source": [
    "y_pred= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "3Ge0-zb_3oBA"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPHPCjd33dEf",
    "outputId": "93db267c-5f27-4ccf-a27f-eed8507e651c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       905\n",
      "           1       0.81      0.84      0.83       952\n",
      "\n",
      "    accuracy                           0.82      1857\n",
      "   macro avg       0.82      0.82      0.82      1857\n",
      "weighted avg       0.82      0.82      0.82      1857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z36fQr4A3l-L"
   },
   "source": [
    "### The f1 score is a parameter similar to accuracy but it tells us how good each class was predicted, and the prediction accuracy of both skilled and unskilles class is above 80 which is pretty good. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Rev1-1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
